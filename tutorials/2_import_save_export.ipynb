{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import, save and export data\n",
    "\n",
    "\n",
    "In this notebook, we look at import functions and how to assign data to the grid. \n",
    "\n",
    "---\n",
    "\n",
    "We import the class (as explained in turorial 1): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from agrid.agrid import *\n",
    "from agrid.acc import download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make two grid objects, one of the Antarctic continent in  [EPSG:3031. WGS 84 / Antarctic Polar Stereographic projection](https://epsg.io/3031) and also a global model, using [WGS84](https://epsg.io/4326). Resolution is defined in the unit of the projection, meters for stereographic projection, and degrees for the global grid. The coordinates in the xarray dataset are stored as dask arrays, they are not loaded until they are needed. When processed, they are loaded as smaller chunks, 1/10 of the axes large. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continental\n",
    "ant = Grid(crs=3031, res = [10*km, 10*km], \n",
    "           left = -3100*km, up=3100*km, right = 3100*km, down = -3100*km, \n",
    "           set_frame = False)\n",
    "\n",
    "print(ant.ds)\n",
    "\n",
    "#Global (almost)\n",
    "world = Grid(crs=4326, res = [1, 1], left = -180, up=90, right = 180, down = -90)\n",
    "\n",
    "print(world.ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We download a raster, in this case the global 1:50m Bathymetry. It is about 100Mb, so it might take a while.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_name:  /Users/tobiasstal/proj/grid/grid/tutorialsHYP_50M_SR_W.zip\n",
      "File /Users/tobiasstal/proj/grid/grid/tutorialsHYP_50M_SR_W.zip already exists.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "stat: path should be string, bytes, os.PathLike or integer, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fa3ebafdb789>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m download('''https://www.naturalearthdata.com/http//\n\u001b[1;32m      2\u001b[0m     www.naturalearthdata.com/download/50m/raster/HYP_50M_SR_W.zip''',\n\u001b[0;32m----> 3\u001b[0;31m          '../../../data/ne/HYP_50M_SR_W.zip')\n\u001b[0m",
      "\u001b[0;32m~/proj/grid/grid/agrid/acc.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, data_files, f_name, un_pack, unpack_path, check_first, block_size, confirm_data, make_meta, meta_dict)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;31m# Check that we got the file(s) and make meta files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata_files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saved: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmake_meta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/genericpath.py\u001b[0m in \u001b[0;36misfile\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m\"\"\"Test whether a path is a regular file\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: stat: path should be string, bytes, os.PathLike or integer, not list"
     ]
    }
   ],
   "source": [
    "download('''https://www.naturalearthdata.com/http//\n",
    "    www.naturalearthdata.com/download/50m/raster/HYP_50M_SR_W.zip''',\n",
    "         '../../../data/ne/HYP_50M_SR_W.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the raster to the global grid and to the Antarctic grid: \n",
    "The raster has three channels, so we assign it to X, Y and RGB coordinates. This might also take some time, as the raster needs to be warped to each grid cell. We can speed up a bit by subsampling the raster before warp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.ds['RGB_RASTER'] = (('Y', 'X', 'RGB'), \n",
    "                world.read_raster('../../data/ne/HYP_50M_SR_W/HYP_50M_SR_W.tif', sub_sampling=5) )\n",
    "world.map_grid('RGB_RASTER')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ant.ds['RGB_RASTER'] = (('Y', 'X', 'RGB'), \n",
    "                        ant.read_raster('../../data/ne/HYP_50M_SR_W/HYP_50M_SR_W.tif', \n",
    "                                                           sub_sampling=3) )\n",
    "\n",
    "ant.map_grid('RGB_RASTER', draw_coast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function read_raster returns a numpy array, that is assigned to the dataFrame and liked to coordinates (Y, X, and RGB). As explaned earlier, Y comes before X as arrays are indexed rows-columns. \n",
    "\n",
    "sub_sampling subsamples unnecisary large arrays before reprojecting. Source extra adds some extra cells around the margin to ensure that the dateline is correctely rendered. \n",
    "\n",
    "Pretty, but the raison d'etre for this code is to work properly with 3D models. We download AN-1S sesimic 3D model of the Antarctic lithosphere. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download('http://www.seismolab.org/model/antarctica/lithosphere/AN1-S_depth_grd.tar.gz',\n",
    "         '../../data/an/AN1-S_depth_grd.tar.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "an_files = sorted(glob.glob('../../data/an/*.grd'))\n",
    "#print(an_files)\n",
    "ant.ds.coords['AN_Z'] = [np.float32(d[-9:-4])*km for d in an_files]\n",
    "str_depths = [str(d[-9:-4]) for d in an_files]\n",
    "\n",
    "\n",
    "an_array = np.empty((ant.nx, ant.ny, len(an_files)))\n",
    "an_array[:] = np.nan\n",
    "for i, a in enumerate(ant.ds.coords['AN_Z'].values):\n",
    "    print(a//km, end=' ')\n",
    "    fname = '../../data/an/AN1-S_hslice_%s.grd'%str_depths[i]\n",
    "    if os.path.isfile(fname):\n",
    "        an_array[:,:,i] = ant.read_grid(fname, xyz = ('x','y','z') ) \n",
    "    \n",
    "ant.ds['AN_S'] = (('Y', 'X', 'AN_Z'), an_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ant.map_grid(ant.ds['AN_S'].sel(AN_Z=150*km), cmap='magma_r', line_w=2, line_c='w', cbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we want to look at a 1D velocity model, e.g. [AK135, Kennett, Engdahl & Buland (1995)](http://rses.anu.edu.au/seismology/ak135/ak135f.html). We can read directely from IRIS url and import it to our grid: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download('http://ds.iris.edu/files/products/emc/data/AK135F/AK135F_AVG.csv',\n",
    "         '../local/AK135F_AVG.csv')\n",
    "\n",
    "\n",
    "ak_135_d, _, ak_135_vp, ak_135_vs,_,_  = np.genfromtxt( '../local/AK135F_AVG.csv', delimiter=',', unpack=True)*km #To SI unit\n",
    "\n",
    "plt.plot(ak_135_vs, -ak_135_d/km)\n",
    "plt.show()\n",
    "\n",
    "ant.ds.coords['AK135_Z'] = ak_135_d\n",
    "ant.ds['AK135_SV'] = (('AK135_Z'), ak_135_vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we want to compare AN_S model with AK135 at 315km, but the depth value is not defined in AK135. Matplotlib can be used directely on the agrid object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ant.ds['AK135_SV_LITH'] = ( ('AN_Z'), \n",
    "                           ant.change_coord(ant.ds['AK135_SV'], ant.ds['AK135_Z'], ant.ds['AN_Z'], axis=-1) )\n",
    "\n",
    "An = ant.ds['AN_S'].mean(dim=['X', 'Y'])*km\n",
    "\n",
    "plt.plot(ant.ds['AK135_SV_LITH'], -ant.ds['AN_Z']/km, An, -ant.ds['AN_Z']/km)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up a toy example. We would like to use AK135 to calculate the perturbation in AN1-S, but only for West Antarctica. We have a shapefile that defines the area we are interested in: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ant.ds['WEST_ANTARCTICA'] = (('Y', 'X'),\n",
    "                            0 < ant.assign_shape('../data/west_antarctica_defined.shp', 'Land'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't worry about the warning. There are probably some crossing vertecies somewhere in the coast line. \n",
    "\n",
    "We use ´where´ to only select cells where `ant.ds['WEST_ANTARCTICA']` is `TRUE`. Here, we use index to select depth slice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ant.map_grid(ant.ds['WEST_ANTARCTICA'], cmap='magma_r', figsize=(5,5))\n",
    "\n",
    "#3D from vector import\n",
    "\n",
    "#Subsampling lo res with high res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this boolean grid to select parts of datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ant.map_grid(ant.ds['RGB_RASTER'].where(ant.ds['WEST_ANTARCTICA']), figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ant.ds['WEST_SEL'] = ant.ds['AN_S'].where(ant.ds['WEST_ANTARCTICA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also import 1-band rasters, eg Bedmap ice sheet thickness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ant.ds['ICE'] = (('Y', 'X'), \n",
    "                ant.read_raster('../../../data/bedmap2_tiff/bedmap2_thickness.tif', no_data = 32767.) )\n",
    "\n",
    "ant.map_grid(ant.ds['ICE'], cmap='magma_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have populated our grid object with a number of datasets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ant.ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save data arrays as netCDF or GMT grids: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ant.grid_to_grd(ant.ds['RGB'], save_name='rgb.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to geotiff: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ant.ds['RGB_RASTER'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ant.grid_to_raster('RGB_RASTER', save_name ='rgb.tif')\n",
    "ant.grid_to_raster('ICE', save_name ='ice.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the complete class object can also be handy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(ant, open( \"ant.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ant = None\n",
    "ant.ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "ant = pickle.load( open( \"ant.p\", \"rb\" ) )\n",
    "print(ant.ds)\n",
    "print(ant.nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes a json file with the parameters is useful: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ant.save_info(file_name='ant.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or the frame in ascii format, for some GIS applications. This is a first example of a suite of export functions used to extract data from the grid. E.g. Red channel from RGB raster: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ant.grid_to_ascii(ant.ds['RGB_RASTER'][:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download('http://www.seismolab.org/model/antarctica/lithosphere/AN1-CRUST.tar.gz', \n",
    "                  'lithosphere/AN1-CRUST.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
