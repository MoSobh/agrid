{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morse grid imports\n",
    "\n",
    "Here we look at applied examples to import data for use in Dr Peter Morse 3D visualtsation software _(in prep.)_. Data must be exported as $1800 \\times 3600$ px png files. This might change in future. \n",
    "\n",
    "Generally, the code in this tutorial runs rather slow as there is a large amount of interpolation. Have patience. \n",
    "\n",
    "Folder `../local` is used to download data and export pngs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "#config_file = \"../agrid/agrid.py\"\n",
    "#with open(config_file) as f:\n",
    "#    code = compile(f.read(), config_file, 'exec')\n",
    "#    exec(code, globals(), locals())\n",
    "\n",
    "# ... or use you Python path or present working directory:\n",
    "import sys, os\n",
    "sys.path.append('..')\n",
    "\n",
    "from agrid.grid import Grid\n",
    "from agrid.acc import download\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import vtk\n",
    "from vtk.util.numpy_support import vtk_to_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agrid.features.morse_2019 import export_morse_png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMEAN\n",
    "\n",
    "Download the mantel model from from Becker and Boschi, The University of Texas at Austin. See original paper [Becker and_Boschi 2002](http://www-udc.ig.utexas.edu/external/becker/becker_and_boschi_2002.pdf) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘../../data/smean/smean_grd.tgz’ already there; not retrieving.\n",
      "x smean/\n",
      "x smean/dvs.8.grd\n",
      "x smean/dvs.15.grd\n",
      "x smean/dvs.29.grd\n",
      "x smean/dvs.17.grd\n",
      "x smean/dvs.28.grd\n",
      "x smean/convert\n",
      "x smean/dvs.27.grd\n",
      "x smean/dvs.22.grd\n",
      "x smean/dvs.20.grd\n",
      "x smean/dvs.6.grd\n",
      "x smean/dvs.11.grd\n",
      "x smean/dvs.1.grd\n",
      "x smean/dvs.13.grd\n",
      "x smean/depths.dat\n",
      "x smean/dvs.9.grd\n",
      "x smean/dvs.24.grd\n",
      "x smean/dvs.7.grd\n",
      "x smean/dvs.14.grd\n",
      "x smean/dvs.4.grd\n",
      "x smean/dvs.23.grd\n",
      "x smean/README\n",
      "x smean/dvs.5.grd\n",
      "x smean/dvs.19.grd\n",
      "x smean/dvs.16.grd\n",
      "x smean/dvs.25.grd\n",
      "x smean/dvs.10.grd\n",
      "x smean/dvs.21.grd\n",
      "x smean/dvs.12.grd\n",
      "x smean/dvs.18.grd\n",
      "x smean/dvs.26.grd\n",
      "x smean/dvs.2.grd\n",
      "x smean/dvs.3.grd\n"
     ]
    }
   ],
   "source": [
    "! mkdir -p ../../data/smean\n",
    "! wget -nc http://www-udc.ig.utexas.edu/external/becker/ftp/smean_grd.tgz \\\n",
    "    -O ../../data/smean/smean_grd.tgz\n",
    "! tar -xvzf ../../data/smean/smean_grd.tgz -C ../../data/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the data is global and we define a grid with the right rsolution from start. However, as we will see later, we could work on regional data as well. The exported png will always have a global coverage with alpha covering the excluded areas. \n",
    "\n",
    "We read depth values for smean from a provided ascii file. However we also have a regular depth dimention, defined as regular 50km depths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[      0   20000   40000   60000   80000  100000  120000  140000  160000\n",
      "  180000  200000  220000  240000  260000  280000  300000  320000  340000\n",
      "  360000  380000  400000  420000  440000  460000  480000  500000  520000\n",
      "  540000  560000  580000  600000  620000  640000  660000  680000  700000\n",
      "  720000  740000  760000  780000  800000  820000  840000  860000  880000\n",
      "  900000  920000  940000  960000  980000 1000000 1050000 1100000 1150000\n",
      " 1200000 1250000 1300000 1350000 1400000 1450000 1500000 1550000 1600000\n",
      " 1650000 1700000 1750000 1800000 1850000 1900000 1950000 2000000 2050000\n",
      " 2100000 2150000 2200000 2250000 2300000 2350000 2400000 2450000 2500000\n",
      " 2550000 2600000 2650000 2700000 2750000 2800000]\n"
     ]
    }
   ],
   "source": [
    "#columns from left to right represent radius,depth,density,Vpv,Vph,Vsv,Vsh,eta,Q-mu,Q-kappa\n",
    "km = 1000\n",
    "\n",
    "\n",
    "\n",
    "smean_depths = km * np.loadtxt('../../data/smean/depths.dat')[::-1]\n",
    "max_depth = np.max(smean_depths)\n",
    "\n",
    "depths = km * np.array([*range(0, 1000, 20)] + [*range(1000, int(max_depth)//km, 50)])\n",
    "\n",
    "prem_d, prem_vsv, prem_vsh = km * np.loadtxt('../../../data/models/PREM_1s.csv', \n",
    "                              delimiter = ',', \n",
    "                              usecols = [1, 5, 6],\n",
    "                              unpack=True)\n",
    "\n",
    "prem_vsv = prem_vsv[prem_d < max_depth]\n",
    "prem_vsh = prem_vsh[prem_d < max_depth]\n",
    "prem_d = prem_d[prem_d < max_depth]\n",
    "\n",
    "print(depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (RGB: 3, X: 3601, X_edge: 3602, Y: 1801, Y_edge: 1802, Z: 87, Z_edge: 88)\n",
      "Coordinates:\n",
      "  * X        (X) float32 -180.0 -179.9 -179.8 -179.7 ... 179.7 179.8 179.9 180.0\n",
      "  * Y        (Y) float32 -90.0 -89.9 -89.8 -89.7 -89.6 ... 89.7 89.8 89.9 90.0\n",
      "  * Z        (Z) float32 0.0 20000.0 40000.0 ... 2700000.0 2750000.0 2800000.0\n",
      "  * X_edge   (X_edge) float32 -180.04997 -179.94998 ... 179.94998 180.04997\n",
      "  * Y_edge   (Y_edge) float32 -90.04995 -89.94995 ... 89.94995 90.04995\n",
      "  * Z_edge   (Z_edge) float64 -1e+04 1e+04 3e+04 ... 2.775e+06 2.825e+06\n",
      "  * RGB      (RGB) <U1 'R' 'G' 'B'\n",
      "    XV       (Y, X) float32 dask.array<shape=(1801, 3601), chunksize=(180, 360)>\n",
      "    YV       (Y, X) float32 dask.array<shape=(1801, 3601), chunksize=(180, 360)>\n",
      "    lat      (Y, X) float32 dask.array<shape=(1801, 3601), chunksize=(180, 360)>\n",
      "    lon      (Y, X) float32 dask.array<shape=(1801, 3601), chunksize=(180, 360)>\n",
      "Data variables:\n",
      "    *empty*\n"
     ]
    }
   ],
   "source": [
    "world = Grid(crs_tgt = 4326, \n",
    "             left= -180, up=90, down= -90, right=180.0, \n",
    "             res=(0.09995,0.0999), \n",
    "             depths = depths)\n",
    "\n",
    "array = np.empty((world.ny, world.nx, world.ds.coords['Z'].size))\n",
    "array[:] = np.nan\n",
    "print(world.ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.ds['PREM_VSV'] = (('Z'), world.change_coord(prem_vsv, prem_d, 'Z') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can read SMEAN files. set_center alows us to read 0-360 as -180 - 180 lon. read_grid uses default nearest neighbour interpolation of datapoints to fit the predefined Morse grid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0, 150.0, 250.0, 350.0, 450.0, 550.0, 650.0, 750.0, 850.0, 950.0, 1050.0, 1150.0, 1250.0, 1350.0, 1450.0, 1550.0, 1650.0, 1750.0, 1850.0, 1950.0, 2050.0, 2150.0, 2250.0, 2350.0, 2450.0, 2550.0, 2650.0, 2750.0, 2850.0, "
     ]
    }
   ],
   "source": [
    "smean_array = np.empty((world.ny, world.nx, smean_depths.size))\n",
    "\n",
    "for i, a in enumerate(smean_depths):\n",
    "    print(a//km, end=', ')\n",
    "    index_name = smean_depths//km - i # Get right file name for each depth\n",
    "    fname = '../../data/smean/dvs.%s.grd'%(i+1)\n",
    "    if os.path.isfile(fname):\n",
    "        smean_array[:,:,i] = world.read_grid(fname, xyz = ('lon','lat','z'), set_center = True)\n",
    "        \n",
    "#array /= 100    #\"The grid file values are given are percentage v_S wave \n",
    "#                #speed variation related to PREM, with layer averages removed.\"\n",
    "        \n",
    "#world.ds['SMEAN'] = (('Y', 'X', 'Z'), array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we export the 3D grids as png files for each depth slice. We store a set of original depth slices in ''morse/smean/z_orig/' and also the interpolated depth slices in 'morse/smean/z_even/'. This might take some time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smean_min = np.nanmin(smean_array)\n",
    "smean_max = np.nanmax(smean_array)\n",
    "\n",
    "print(smean_min, smean_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_smean_array  = world.change_coord(smean_array, old=smean_depths, new='Z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(new_smean_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.ds['SMEAN'] = (('Y', 'X', 'Z'), new_smean_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(world, open( \"../local/world_size.p\", \"wb\" ), protocol=4)\n",
    "#world = pickle.load( open( \"../local/world.p\", \"rb\" ) )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p ../local/morse/smean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, z in enumerate(world.ds['Z'][::-1]):\n",
    "    report = export_morse_png(world,\n",
    "                        data = world.ds['SMEAN'].isel(Z=i).values, \n",
    "                        png_name = '../local/morse/smean/%04d_smean.png'%(int(z)//km), \n",
    "                        v_min = -10, v_max = 10, \n",
    "                        png_format = 'RGB',\n",
    "                        set_geometry = False)\n",
    "    print(report)\n",
    "    with open(\"../local/morse/smean/log_smean.txt\", \"a\") as log_file:\n",
    "        log_file.write(report)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLAD M15\n",
    "\n",
    "Now let's import the model from [Bozdağ et al (2016)](https://academic.oup.com/gji/article/207/3/1739/2404568). Unfortunately, it appears that the data is not availible from any open repo (?!), but I belive that the group is willing to assist if contacted. \n",
    "\n",
    "The SMEAN data was easy to import, but exporting the GLAD-M15 data is more compicated as I only get access to an unstructured grid, in a normalised space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a vtk file to reader\n",
    "reader = vtk.vtkXMLUnstructuredGridReader()\n",
    "reader.SetFileName('../local/GLAD-M15/reg_1_dvsv.vtu')\n",
    "reader.Update()\n",
    "\n",
    "# Get the coordinates of nodes in the mesh\n",
    "nodes_vtk_array= reader.GetOutput().GetPoints().GetData()\n",
    "\n",
    "#The data field is the first scalar in the vtu file\n",
    "data_vtk_array = reader.GetOutput().GetPointData().GetArray(0)\n",
    "\n",
    "print(data_vtk_array, nodes_vtk_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get two arrays. Note that sizes are equal (Number Of Tuples: 4712064 and Number Of Tuples: 4712064) and the coordinate are 3D (NumberOfComponents: 3). Read coordinates and data as numpy arrays and have a look: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_numpy_array = vtk_to_numpy(nodes_vtk_array)\n",
    "X, Y, Z = nodes_numpy_array[:,0] , nodes_numpy_array[:,1] , nodes_numpy_array[:,2]\n",
    "V = vtk_to_numpy(data_vtk_array)\n",
    "\n",
    "print(X[:10],Y[:10],Z[:10],V[:10], sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coordinates are stored in the range [-1..1]. We assume a spherical Earth and compute an array with every points distance from centre. Function `sphere_to_layer()` takes a slice from the sphere and save to a 2D array. delta_r should be as small as possible, for best vertical resolution, but if too few points are used the vertical resolution gets bad. \n",
    "\n",
    "We loop through the harmonics of the sphere and read all points within a spherical shell defined by the radius +/- delta_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sphere_to_layer(d, R, V, LAT, LON, xxx, yyy, \n",
    "                    delta_r = 32*km, \n",
    "                    min_s = 5000,\n",
    "                    r_earth =  (6357*km + 6378*km) / 2, \n",
    "                    interpolation = 'nearest'):\n",
    "    \n",
    "    A = np.zeros_like(xxx).astype('float')\n",
    "    A[:] = np.nan\n",
    "    upper = 1-(d-delta_r)/r_earth\n",
    "    lower = 1-(d+delta_r)/r_earth\n",
    "    S = (R > lower) & (R < upper) # Select points in spherical shell\n",
    "    s_sum = np.count_nonzero(S) # Check how many points in shell\n",
    "\n",
    "    if s_sum >= min_s:\n",
    "        A = interpolate.griddata((LON[S], LAT[S]),\n",
    "                V[S], (xxx, yyy), method = interpolation)\n",
    "    print(d//1000, 'km \\t N=', sum(S),u'\\t \\N{BLACK RIGHT-POINTING TRIANGLE}', np.nanmean(A))\n",
    "    return np.flipud(A) #Because ulike lat, rows start from top. \n",
    "\n",
    "R = np.sqrt(X*X + Y*Y + Z*Z) # The distance from each point to centre of spherical Earth. \n",
    "\n",
    "LAT = world.shape3[0]/180 * (np.arccos( Z / R) * 180/np.pi) \n",
    "LON = world.shape3[1]/360 * (np.arctan2(Y, X) * 180/np.pi + 180)\n",
    "\n",
    "xxx, yyy = np.meshgrid(range(0, world.shape3[1]), range(world.shape3[0], 0, -1)) \n",
    "\n",
    "glad = np.zeros(world.shape3) # self.shape3 is a tuple of the models dimensions\n",
    "\n",
    "for i, d in enumerate(world.ds['Z'].values):\n",
    "    glad[:,:,i] = sphere_to_layer(d, R, V, LAT, LON, xxx, yyy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately there are not enugh data points at 1350, 1450, 2150 and 2250 km depth. We'd need to look in a broad spherical shell to get datapoints: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_i, missing_d = [], []\n",
    "\n",
    "for i in range(glad.shape[2]):\n",
    "    if (np.count_nonzero(np.isnan(glad[:,:,i]) ) > 1000):\n",
    "        missing_i.append(i)\n",
    "        missing_d.append(world.ds['Z'].values[i])\n",
    "      \n",
    "for i,d in zip(missing_i, missing_d):\n",
    "    print(i, end=' ')\n",
    "    glad[:,:,i] = sphere_to_layer(d, R, V, LAT, LON, xxx, yyy, delta_r = 45*km)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we can be more precise with the first layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glad[:,:,0] = sphere_to_layer(50*km, R, V, LAT, LON, xxx, yyy, delta_r = 14*km)   \n",
    "glad[:,:,1] = sphere_to_layer(150*km, R, V, LAT, LON, xxx, yyy, delta_r = 20*km)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the array to the object and have a look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.ds['GLAD'] = (('Y', 'X', 'Z'), glad)\n",
    "glad_min = np.nanmin(world.ds['GLAD'].values)\n",
    "glad_max = np.nanmax(world.ds['GLAD'].values)\n",
    "\n",
    "print(glad_min, glad_max)\n",
    "#print(smean_min, smean_max)\n",
    "\n",
    "z_map = 0\n",
    "world.map_grid(world.ds['GLAD'].isel(Z=z_map), cmap='magma_r', vmin=-0.06, vmax=0.06)\n",
    "#world.map_grid(world.ds['SMEAN'].isel(Z=z_map), cmap='magma_r', vmin=-0.06, vmax=0.06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.ds['DIFF'] = world.ds['GLAD']-world.ds['SMEAN']\n",
    "\n",
    "diff_min = np.nanmin(world.ds['DIFF'].values)\n",
    "diff_max = np.nanmax(world.ds['DIFF'].values)\n",
    "\n",
    "print(diff_min, diff_max)\n",
    "\n",
    "world.map_grid(world.ds['DIFF'].isel(Z=z_map), cmap='BrBG', vmin=-0.06, vmax=0.06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p ../local/glad/16_bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, z in enumerate(world.ds['Z']):\n",
    "    report = export_morse_png(world, world.ds['GLAD'].isel(Z=i).values, '../local/glad/16_bit/%04d_%s_glad.png'%(int(z)//km, i+1), \n",
    "                          v_min = glad_min, v_max = glad_max, \n",
    "                              set_geometry = False, \n",
    "                             png_format = 'RGB', \n",
    "                             bit_depth = 16)\n",
    "    with open(\"../local/morse/glad/log_16bit.txt\", \"a\") as log_file:\n",
    "        log_file.write(report)\n",
    "    print(report)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the grid: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.save(world.ds, '../local/smean_and_glad.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also interpolate new depth values to make a regular 3D grid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.ds['Z_NEW'] = range(0,2850*km, 100*km)\n",
    "\n",
    "world.ds['SMEAN_INTER'] = ( ('Y', 'X', 'Z'), \n",
    "                           world.change_coord(world.ds['SMEAN'], world.ds['Z'], world.ds['Z_NEW']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AuSREM\n",
    "\n",
    "Australian crustal and lithospheric seismic model.\n",
    "\n",
    "Can be downloaded from http://rses.anu.edu.au/seismology/AuSREM/Downloads/ We assume a local file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '../local/ausrem_SV_100.txt'\n",
    "data = world.read_ascii(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a mask, as the 'nearest neigbur' interpolation tested, will extrapolate values to all cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_master = np.isfinite(data)\n",
    "\n",
    "plt.imshow(alpha_master)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we test a number of different formats for the output png file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _format in ['L', 'LA', 'RGB', 'RGBA']:\n",
    "    for _bit_depth in [8, 16]:\n",
    "        for _interpol in ['nearest', 'linear', 'cubic']:\n",
    "            data = world.read_ascii(fname, interpol =_interpol)\n",
    "            \n",
    "            if _interpol == 'nearest':\n",
    "                how_confine = 'mask'\n",
    "                mask_to_value = np.nan\n",
    "            else:\n",
    "                how_confine = 'input'\n",
    "                mask_to_value = None\n",
    "            \n",
    "            report = export_morse_png(world,\n",
    "                          data = data, \n",
    "                          png_format = _format,\n",
    "                          png_name = '../local/AuSREM/AuSREM_100km_%s_%sbit_%s.png'%( _interpol,_bit_depth,_format),\n",
    "                          interpol_method =  _interpol,\n",
    "                          confine_data = how_confine,\n",
    "                          confine_mask = alpha_master,\n",
    "                        mask_to_value = mask_to_value,\n",
    "                          v_min = 4, v_max = 5, \n",
    "                          clip=True,\n",
    "                          set_geometry = False, \n",
    "                          bit_depth=_bit_depth)\n",
    "\n",
    "            print(report)\n",
    "            with open(\"../local/AuSREM_log.txt\", \"a\") as log_file:\n",
    "                log_file.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sips -g all ../local/AuSREM/AuSREM_100km_nearest_16bit_L.png\n",
    "#!open ../local/new/AuSREM_100km_nearest_16bit_L.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.map_grid('SMEAN'.sel(Z=1000) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lon, persent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
